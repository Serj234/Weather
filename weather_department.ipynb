{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrF1a-G21PpT",
        "outputId": "d72f5987-bb49-4eda-8e5b-2079c78d80e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (4500, 6)\n",
            "y shape: (4500, 6)\n",
            "Best parameters: {'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 300}\n",
            "MAPE on test set: 79324780000.0\n",
            "Predictions shape: (4500, 6)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Открытие и загрузка данных\n",
        "if not os.path.exists('weather-forecast-hackathon.zip'):\n",
        "    !wget https://drive.google.com/uc?id=1Vun7-8vmYbSr4COqb1nAGogEIAzInxab -O weather-forecast-hackathon.zip\n",
        "    !unzip weather-forecast-hackathon.zip\n",
        "    !ls -l\n",
        "\n",
        "data = {}\n",
        "data_files = ['temperature.npy', 'pressure.npy', 'humidity.npy', 'wind_speed.npy', 'wind_dir.npy', 'cloud_cover.npy']\n",
        "for file_name in data_files:\n",
        "    data[file_name[:-4]] = np.load(file_name)\n",
        "\n",
        "# Составление матрицы признаков X\n",
        "X = np.stack([data[key] for key in data], axis=-1)\n",
        "X = X.reshape(-1, 6)\n",
        "\n",
        "# Разделение данных на X и y\n",
        "y = X[34200:, :]\n",
        "X = X[:-34200, :]\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)\n",
        "\n",
        "# Предобработка данных\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Добавление новых признаков (например, среднее значение и стандартное отклонение для каждого показателя)\n",
        "X_additional = np.hstack((np.mean(X_scaled, axis=1).reshape(-1, 1), np.std(X_scaled, axis=1).reshape(-1, 1)))\n",
        "X_scaled = np.hstack((X_scaled, X_additional))\n",
        "\n",
        "# Разделение данных на обучающий и тестовый наборы\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Настройка гиперпараметров модели (XGBoost)\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [5, 10, 15],\n",
        "    'learning_rate': [0.01, 0.1, 0.3]\n",
        "}\n",
        "\n",
        "model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='neg_mean_absolute_percentage_error')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "\n",
        "# Обучение модели с лучшими параметрами\n",
        "best_model = grid_search.best_estimator_\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# Оценка модели на тестовом наборе\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "y_pred = best_model.predict(X_test)\n",
        "mape_test = mean_absolute_percentage_error(y_test, y_pred)\n",
        "print(\"MAPE on test set:\", mape_test)\n",
        "\n",
        "# Предсказание для всех данных\n",
        "predictions = best_model.predict(X_scaled)\n",
        "print(\"Predictions shape:\", predictions.shape)\n",
        "\n",
        "# Сохранение предсказаний в CSV\n",
        "solution = pd.DataFrame(predictions, columns=[\"temperature\", \"pressure\", \"humidity\", \"wind_speed\", \"wind_dir\", \"cloud_cover\"])\n",
        "solution.to_csv(\"solution.csv\", index_label=\"ID\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# import os\n",
        "\n",
        "# # Открытие и загрузка данных\n",
        "# if not os.path.exists('weather-forecast-hackathon.zip'):\n",
        "#     !wget https://drive.google.com/uc?id=1Vun7-8vmYbSr4COqb1nAGogEIAzInxab -O weather-forecast-hackathon.zip\n",
        "#     !unzip weather-forecast-hackathon.zip\n",
        "#     !ls -l\n",
        "\n",
        "# data = {}\n",
        "# data_files = ['temperature.npy', 'pressure.npy', 'humidity.npy', 'wind_speed.npy', 'wind_dir.npy', 'cloud_cover.npy']\n",
        "# for file_name in data_files:\n",
        "#     data[file_name[:-4]] = np.load(file_name)\n",
        "\n",
        "# # Составление матрицы признаков X\n",
        "# X = np.stack([data[key] for key in data], axis=-1)\n",
        "# X = X.reshape(-1, 6)\n",
        "\n",
        "# # Разделение данных на X и y\n",
        "# y = X[34200:, :]\n",
        "# X = X[:-34200, :]\n",
        "\n",
        "# # Предобработка данных\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# scaler = StandardScaler()\n",
        "# X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# # Добавление новых признаков (например, среднее значение и стандартное отклонение для каждого показателя)\n",
        "# X_additional = np.hstack((np.mean(X_scaled, axis=1).reshape(-1, 1), np.std(X_scaled, axis=1).reshape(-1, 1)))\n",
        "# X_scaled = np.hstack((X_scaled, X_additional))\n",
        "\n",
        "# # Разделение данных на обучающий и тестовый наборы\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# # Настройка гиперпараметров модели (XGBoost) с помощью случайного поиска\n",
        "# import xgboost as xgb\n",
        "# from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# param_grid = {\n",
        "#     'n_estimators': np.arange(100, 1000, 100),\n",
        "#     'max_depth': np.arange(3, 10),\n",
        "#     'learning_rate': np.linspace(0.01, 0.3, 10)\n",
        "# }\n",
        "\n",
        "# model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
        "# random_search = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter=50, cv=5, scoring='neg_mean_absolute_percentage_error', random_state=42)\n",
        "# random_search.fit(X_train, y_train)\n",
        "\n",
        "# print(\"Best parameters:\", random_search.best_params_)\n",
        "\n",
        "# # Обучение модели с лучшими параметрами\n",
        "# best_model = random_search.best_estimator_\n",
        "# best_model.fit(X_train, y_train)\n",
        "\n",
        "# # Оценка модели на тестовом наборе\n",
        "# from sklearn.metrics import mean_absolute_percentage_error\n",
        "# y_pred = best_model.predict(X_test)\n",
        "# mape_test = mean_absolute_percentage_error(y_test, y_pred)\n",
        "# print(\"MAPE on test set:\", mape_test)\n",
        "\n",
        "# # Предсказание для всех данных\n",
        "# predictions = best_model.predict(X_scaled)\n",
        "# print(\"Predictions shape:\", predictions.shape)\n",
        "\n",
        "# # Сохранение предсказаний в CSV\n",
        "# solution = pd.DataFrame(predictions, columns=[\"temperature\", \"pressure\", \"humidity\", \"wind_speed\", \"wind_dir\", \"cloud_cover\"])\n",
        "# solution.to_csv(\"solution.csv\", index_label=\"ID\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ksu56yY5krD",
        "outputId": "2a5b0b5c-b964-4927-83ac-03b06464d504"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'n_estimators': 300, 'max_depth': 7, 'learning_rate': 0.23555555555555557}\n",
            "MAPE on test set: 702859600000.0\n",
            "Predictions shape: (4500, 6)\n"
          ]
        }
      ]
    }
  ]
}